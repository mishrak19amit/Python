{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Predicting UPSC rank using linear regression of Pyspark\n",
    "#!pip install Bio\n",
    "#!pip install biopython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"Predicting_upsc_rank\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsc_data=spark.read.csv(\"/home/moglix/Desktop/Amit/PGitHub/Python/UPSC_Result/CSM18_FQ_WEB_CELL_NEW.csv\",inferSchema=True,header=True)\n",
    "#upsc_data=upsc_data.drop(['ROLL_NO', 'NAME'])\n",
    "#Dropping roll_num and name because it's not a important feature\n",
    "columns_to_drop = ['ROLL_NO', 'NAME']\n",
    "upsc_data = upsc_data.drop(*columns_to_drop)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------+-------+----+\n",
      "|CATEGORY|PT_MARKS|MAIN_MARKS|F_TOTAL|RANK|\n",
      "+--------+--------+----------+-------+----+\n",
      "|      SC|     179|       942|   1121|   1|\n",
      "|      UR|     198|       882|   1080|   2|\n",
      "|      UR|     184|       893|   1077|   3|\n",
      "|      UR|     184|       887|   1071|   4|\n",
      "|      UR|     173|       895|   1068|   5|\n",
      "|      UR|     184|       883|   1067|   6|\n",
      "|      UR|     182|       885|   1067|   7|\n",
      "|      UR|     195|       871|   1066|   8|\n",
      "|      UR|     193|       871|   1064|   9|\n",
      "|      UR|     187|       877|   1064|  10|\n",
      "|      UR|     193|       870|   1063|  11|\n",
      "|      UR|     171|       891|   1062|  12|\n",
      "|      UR|     165|       897|   1062|  13|\n",
      "|      UR|     182|       879|   1061|  14|\n",
      "|      UR|     206|       854|   1060|  15|\n",
      "|     OBC|     176|       884|   1060|  16|\n",
      "|      UR|     193|       866|   1059|  17|\n",
      "|      UR|     180|       879|   1059|  18|\n",
      "|      UR|     171|       887|   1058|  19|\n",
      "|      UR|     193|       864|   1057|  20|\n",
      "+--------+--------+----------+-------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#upsc_data=upsc_data.na.fill(\"UR\", \"CATEGORY\")\n",
    "# Filling null value for Category to best fit in feature model\n",
    "colname=[\"CATEGORY\"]\n",
    "upsc_data=upsc_data.na.fill(\"UR\",colname);\n",
    "upsc_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because Category is a String so need to reindex it as a double to fit in feature model\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "indexer=StringIndexer(inputCol='CATEGORY', outputCol='CATEGORY_cat')\n",
    "indexed=indexer.fit(upsc_data).transform(upsc_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------+----------+-------+----+------------+\n",
      "|CATEGORY|PT_MARKS|MAIN_MARKS|F_TOTAL|RANK|CATEGORY_cat|\n",
      "+--------+--------+----------+-------+----+------------+\n",
      "|      SC|     179|       942|   1121|   1|         2.0|\n",
      "|      UR|     198|       882|   1080|   2|         0.0|\n",
      "|      UR|     184|       893|   1077|   3|         0.0|\n",
      "|      UR|     184|       887|   1071|   4|         0.0|\n",
      "|      UR|     173|       895|   1068|   5|         0.0|\n",
      "|      UR|     184|       883|   1067|   6|         0.0|\n",
      "|      UR|     182|       885|   1067|   7|         0.0|\n",
      "|      UR|     195|       871|   1066|   8|         0.0|\n",
      "|      UR|     193|       871|   1064|   9|         0.0|\n",
      "|      UR|     187|       877|   1064|  10|         0.0|\n",
      "|      UR|     193|       870|   1063|  11|         0.0|\n",
      "|      UR|     171|       891|   1062|  12|         0.0|\n",
      "|      UR|     165|       897|   1062|  13|         0.0|\n",
      "|      UR|     182|       879|   1061|  14|         0.0|\n",
      "|      UR|     206|       854|   1060|  15|         0.0|\n",
      "|     OBC|     176|       884|   1060|  16|         1.0|\n",
      "|      UR|     193|       866|   1059|  17|         0.0|\n",
      "|      UR|     180|       879|   1059|  18|         0.0|\n",
      "|      UR|     171|       887|   1058|  19|         0.0|\n",
      "|      UR|     193|       864|   1057|  20|         0.0|\n",
      "+--------+--------+----------+-------+----+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "indexed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----+\n",
      "|             feature|RANK|\n",
      "+--------------------+----+\n",
      "|[179.0,942.0,1121...|   1|\n",
      "|[198.0,882.0,1080...|   2|\n",
      "|[184.0,893.0,1077...|   3|\n",
      "|[184.0,887.0,1071...|   4|\n",
      "|[173.0,895.0,1068...|   5|\n",
      "|[184.0,883.0,1067...|   6|\n",
      "|[182.0,885.0,1067...|   7|\n",
      "|[195.0,871.0,1066...|   8|\n",
      "|[193.0,871.0,1064...|   9|\n",
      "|[187.0,877.0,1064...|  10|\n",
      "|[193.0,870.0,1063...|  11|\n",
      "|[171.0,891.0,1062...|  12|\n",
      "|[165.0,897.0,1062...|  13|\n",
      "|[182.0,879.0,1061...|  14|\n",
      "|[206.0,854.0,1060...|  15|\n",
      "|[176.0,884.0,1060...|  16|\n",
      "|[193.0,866.0,1059...|  17|\n",
      "|[180.0,879.0,1059...|  18|\n",
      "|[171.0,887.0,1058...|  19|\n",
      "|[193.0,864.0,1057...|  20|\n",
      "+--------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Training model based on Main_marks, PT_marks, and Category, and total marks considering these a a feature\n",
    "# Rank is the output \n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler=VectorAssembler(inputCols=['PT_MARKS', \n",
    " 'MAIN_MARKS', \n",
    " 'F_TOTAL', \n",
    " 'CATEGORY_cat'], outputCol='feature')\n",
    "output=assembler.transform(indexed)\n",
    "output.select('feature','RANK').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training data model in 80% and 20% ratio\n",
    "final_data=output.select('feature','RANK')\n",
    "train_data, test_data=final_data.randomSplit([0.8,0.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              RANK|\n",
      "+-------+------------------+\n",
      "|  count|               607|\n",
      "|   mean| 380.7199341021417|\n",
      "| stddev|221.24004103482565|\n",
      "|    min|                 1|\n",
      "|    max|               759|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|              RANK|\n",
      "+-------+------------------+\n",
      "|  count|               152|\n",
      "|   mean|           377.125|\n",
      "| stddev|211.79636329104244|\n",
      "|    min|                 2|\n",
      "|    max|               751|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rsquared Error : 0.8740538013781964\n"
     ]
    }
   ],
   "source": [
    "# Using Linear Regression from Spark ML Library\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "ship_lr=LinearRegression(featuresCol='feature', labelCol='RANK')\n",
    "trainded_ship_model=ship_lr.fit(train_data)\n",
    "ship_result=trainded_ship_model.evaluate(train_data)\n",
    "\n",
    "# Getting accuracy score for trained model\n",
    "print('Score :',ship_result.r2) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(feature=DenseVector([135.0, 792.0, 927.0, 3.0])),\n",
       " Row(feature=DenseVector([138.0, 799.0, 937.0, 2.0])),\n",
       " Row(feature=DenseVector([138.0, 799.0, 937.0, 2.0])),\n",
       " Row(feature=DenseVector([140.0, 829.0, 969.0, 1.0])),\n",
       " Row(feature=DenseVector([143.0, 776.0, 919.0, 2.0])),\n",
       " Row(feature=DenseVector([143.0, 800.0, 943.0, 0.0])),\n",
       " Row(feature=DenseVector([143.0, 800.0, 943.0, 1.0])),\n",
       " Row(feature=DenseVector([143.0, 847.0, 990.0, 0.0])),\n",
       " Row(feature=DenseVector([143.0, 856.0, 999.0, 2.0])),\n",
       " Row(feature=DenseVector([143.0, 861.0, 1004.0, 0.0]))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlabeled_data=test_data.select('feature')\n",
    "unlabeled_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming the test data and pre\n",
    "predictions=trainded_ship_model.transform(unlabeled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------------+\n",
      "|             feature|        prediction|\n",
      "+--------------------+------------------+\n",
      "|[135.0,792.0,927....| 680.1649350009698|\n",
      "|[138.0,799.0,937....| 587.1013679671078|\n",
      "|[138.0,799.0,937....| 587.1013679671078|\n",
      "|[140.0,829.0,969....|411.12647843968534|\n",
      "|[143.0,776.0,919....| 655.0848417246862|\n",
      "|[143.0,800.0,943....|453.67848742286515|\n",
      "|[143.0,800.0,943....| 509.1764725680946|\n",
      "|[143.0,847.0,990....| 276.6248187339488|\n",
      "|[143.0,856.0,999....|353.71689502014715|\n",
      "|[143.0,861.0,1004...| 223.8854280606547|\n",
      "|[146.0,774.0,920....| 651.4231538403137|\n",
      "|[146.0,844.0,990....| 332.2282153286128|\n",
      "|[146.0,850.0,996....|254.12763418054283|\n",
      "|[149.0,767.0,916....| 666.5969626249753|\n",
      "|[149.0,787.0,936....| 646.7529610940696|\n",
      "|[149.0,834.0,983....| 358.7033221146944|\n",
      "|[149.0,841.0,990....| 276.8356416328179|\n",
      "|[151.0,773.0,924....| 692.0284273993734|\n",
      "|[151.0,775.0,926....| 684.4942287317599|\n",
      "|[151.0,777.0,928....|  621.462044918917|\n",
      "+--------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
